<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="learnable module for clean-noisy label splitting, dubbed SplitNet.">
  <meta name="keywords" content="LNL, SSL, SplitNet">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta property="og:image" content="./static/images/main.png">

  <title>SplitNet: Learnable Clean-Noisy Label Splitting for Learning with Noisy Labels</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  
  <link rel="apple-touch-icon" sizes="180x180" href="favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="favicon_io/favicon-16x16.png">
  <link rel="manifest" href="favicon_io/site.webmanifest">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SplitNet: Learnable Clean-Noisy Label Splitting for Learning with Noisy Labels</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=VbcYbMAAAAAJ&hl=ko&oi=sra">Daehwan Kim*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=GatAWO4AAAAJ&hl=ko&oi=sra">Kwangrok Ryoo*</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://orcid.org/0000-0003-4165-5671">Hansang Cho</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://cvlab.korea.ac.kr/">Seungryong Kim</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Samsung Electro-Mechanics,</span>
            <span class="author-block"><sup>2</sup>Korea University</span>
            <!-- <h5> <span class="author-block"><sup>*</sup>These authors contributed equally to this work</span> </h5> -->
          </div>
          <h1 style="font-size:15px">*These authors contributed equally to this work</h1>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2211.11753.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.11753"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link.
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- 티져이미지 -->
<!-- <div class="columns is-centered">
  <img style='height: auto; width: 40%; object-fit: contain' src="static/images/main.png" alt="overview_image">
</div> -->
<!--/ 티져이미지 -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Annotating the dataset with high-quality labels is crucial for deep networks' performance, but in real-world scenarios, the labels are often contaminated by noise. 
          To address this, some methods were recently proposed to automatically split clean and noisy labels among training data, and learn a semi-supervised learner in a Learning with Noisy Labels (LNL) framework. 
          However, they leverage a handcrafted module for clean-noisy label splitting, which induces a confirmation bias in the semi-supervised learning phase and limits the performance. 
          In this paper, for the first time, we present a learnable module for clean-noisy label splitting, dubbed SplitNet, and a novel LNL framework which complementarily trains the SplitNet and main network for the LNL task. 
          We also propose to use a dynamic threshold based on split confidence by SplitNet to optimize the semi-supervised learner better. 
          To enhance SplitNet training, we further present a risk hedging method. 
          Our proposed method performs at a state-of-the-art level, especially in high noise ratio settings on various LNL benchmarks.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div> -->
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <!-- Overall -->
        <div style="text-align:center">
          <h3 class="title is-3">Overall Architecture</h3>
        </div>
        <div class="content has-text-justified">
          <!-- <br><br/> -->
          <p></p> 
          <p>
            After training the main model through a warm-up, we use the proposed risk hedging process to only select confident samples to train SplitNet. 
            With SplitNet, we obtain clean probability and split confidence, and with this information, we train the main model through SSL. 
            Loss distribution generated by the main model is used in risk hedging. 
            The main model and SplitNet can be alternately improved through this iterative process.
          </p>
        </div>
        <div class="columns is-centered">
          <img style='height: auto; width: 80%; object-fit: contain' src="static/images/overall.png" alt="overview_image">
        </div>
        <!--/ Overall -->

        <!-- Experiment -->
        <br><br/>
        <div style="text-align:center">
          <h3 class="title is-3">Experimental Results</h3>
          <p></p> 
        </div>
        <h3 class="title is-5">CIFAR-10/100</h3>
        <div class="content has-text-justified">
          <p></p> 
          <p>
            We report substantial improvements in performance across all evaluated benchmarks, with the increases in performance becoming even more evident in cases where more challenging strong noise ratios are used. 
            Note that compared to DivideMix and AugDesc, where well-performing hyper-parameters differ for cases depending on the strength of the noise ratio, and specifically compared to AugDesc, which has separate well-performing models for cases depending on the strength of the noise ratio (i.e., DM-AugDesc-WS-SAW and DM-Aug-Desc-WS-WAW), our method enhances performance using a single model. 
          </p>
        </div>
        <div class="columns is-centered">
          <img style='height: auto; width: 80%; object-fit: contain' src="static/images/cifar.png" alt="overview_image">
        </div>

        <br><br/> 
        <h3 class="title is-5">CIFAR-10/100 IDN</h3>
        <div class="content has-text-justified">
          <p></p> 
          <p>
            CIFAR10IDN and CIFAR-100IDN are datasets that have synthetically injected part-dependent label noise into CIFAR-10 and CIFAR 100, respectively. 
            They are derived from the fact that humans perceive instances by breaking them down into parts and estimate the IDN transition matrix of an instance as a combination of the transition matrices of different parts of the instance.
          </p>
        </div>
        <div class="columns is-centered">
          <img style='height: auto; width: 80%; object-fit: contain' src="static/images/cifaridn.png" alt="overview_image">
        </div>

        <br><br/> 
        <h3 class="title is-5">CIFAR-10/100 N</h3>
        <div class="content has-text-justified">
          <p></p> 
          <p>
            CIFAR-N equips the training datasets of CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels, which are collected from Amazon Mechanical Turk. 
            Unlike existing real-world noisy datasets, CIFAR-N is a real-world noisy dataset that establishes controllable, easy-to-use, and moderated-sized with both ground-truth and noisy labels.
          </p>
        </div>
        <div class="columns is-centered">
          <img style='height: auto; width: 80%; object-fit: contain' src="static/images/cifarn.png" alt="overview_image">
        </div>
        <!--/ Experiment -->

        <!-- Analysis -->
        <br><br/>
        <div style="text-align:center">
          <h3 class="title is-3">Analysis</h3>
          <p></p> 
        </div>
        <h3 class="title is-5">Accuracy and F1 Score</h3>
        <div class="content has-text-justified">
          <p></p> 
          <p>
            (a), (b), (c), and (d) are the F1 score when the noise ratios are 20%, 50%, 80%, and 90%, respectively. (e), (f), (g), and (h) are the accuracy when the noise ratios are 20\%, 50\%, 80\%, and 90\%, respectively. For all noise ratios, the F1 score and accuracy of SplitNet are higher, which means that SplitNet selects more actually clean data.
          </p>
        </div>
        <div class="columns is-centered">
          <img style='height: auto; width: 80%; object-fit: contain' src="static/images/f1.png" alt="overview_image">
        </div>

        <br><br/> 
        <h3 class="title is-5">Confusion Matrix</h3>
        <div class="content has-text-justified">
          <p></p> 
          <p>
            The horizontal axis represents prediction, and the vertical axis represents ground truth in each confusion matrix. 
            The far-left column shows the results of SplitNet trained through hedging after warm-up, the middle column shows the results of SplitNet trained with data filtered with a fixed threshold, and the far-right column shows the results of GMM. 
            The top row shows results at 0 epoch, and the bottom row shows results at 150.
          </p>
        </div>
        <div class="columns is-centered">
          <img style='height: auto; width: 80%; object-fit: contain' src="static/images/conf.png" alt="overview_image">
        </div>
        <!--/ Analysis -->        

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{kim2022splitnet,
      title={SplitNet: Learnable Clean-Noisy Label Splitting for Learning with Noisy Labels},
      author={Kim, Daehwan and Ryoo, Kwangrok and Cho, Hansang and Kim, Seungryong},
      journal={arXiv preprint arXiv:2211.11753},
      year={2022}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
